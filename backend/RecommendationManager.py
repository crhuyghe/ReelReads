import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import Literal

class RecommendationManager:
    """This class manages book/movie database querying and recommendation algorithms"""
    def __init__(self):
        self._book_embeddings, self._movie_embeddings = self._get_embeddings()
        self._book_ratings, self._movie_ratings = self._get_ratings()
        self._embedding_model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

    def get_recommendations(self, user_vector, user_history, top_n=10):
        """Combines the recommendation techniques to get the top book and movie recommendations for a particular user."""

        movie_sim, book_sim = self._sentiment_analysis_search(user_vector)
        movie_collab, book_collab = None, None

        if len(user_history["movie"].keys()) > 0:
            movie_collab = self._collab_filtering_search(user_history, "movie")
        if len(user_history["book"].keys()) > 0:
            book_collab = self._collab_filtering_search(user_history, "book")

        print(movie_sim)
        print(movie_collab)
        print(book_sim)
        print(book_collab)

        # Try multiplying score values?


    def search_by_query(self, query, top_n=5):
        """Returns the top N most similar books and movies to the provided query."""
        embedding = self._embedding_model.encode(query)
        mdf, bdf = self._sentiment_analysis_search(embedding)

        return mdf.head(top_n), bdf.head(top_n)

    def search_by_movie(self, movie_id, top_n=5):
        """Returns the top N most similar books and movies to the provided movie."""
        movie_embedding = self._movie_embeddings.loc[self._movie_embeddings["id"] == movie_id].iloc[:, 1:].to_numpy()[0]
        mdf, bdf = self._sentiment_analysis_search(movie_embedding)

        return mdf.head(top_n+1).iloc[1:], bdf.head(top_n)

    def search_by_book(self, book_id, top_n=5):
        """Returns the top N most similar books and movies to the provided book."""
        book_embedding = self._book_embeddings.loc[self._book_embeddings["ISBN"] == book_id].iloc[:, 1:].to_numpy()[0]
        mdf, bdf = self._sentiment_analysis_search(book_embedding)

        return mdf.head(top_n), bdf.head(top_n+1).iloc[1:]

    def _get_embeddings(self):
        """Fetches book and movie embeddings."""
        return pd.read_csv("database/book_data/book_embeddings.csv"), pd.read_csv("database/movie_data/movie_embeddings.csv")

    def _get_ratings(self):
        """Fetches book and movie ratings."""
        return pd.read_csv("database/book_data/als_book_ratings.csv"), pd.concat((pd.read_csv("database/movie_data/als_movie_ratings1.csv"), pd.read_csv("database/movie_data/als_movie_ratings2.csv")))

    def _sentiment_analysis_search(self, vec):
        """Runs a sentiment analysis search on the book and movie datasets using the provided embedding vector.
        Returns two pandas dataframes of similarity scores and movie/book identifiers."""
        movie_sim = pd.concat([self._movie_embeddings["id"], pd.DataFrame(cosine_similarity(np.reshape(vec, (1, -1)), self._movie_embeddings.iloc[:, 1:])[0], columns=["sim"])], axis=1)
        book_sim = pd.concat([self._book_embeddings["ISBN"], pd.DataFrame(cosine_similarity(np.reshape(vec, (1, -1)), self._book_embeddings.iloc[:, 1:])[0], columns=["sim"])], axis=1)

        movie_sim.sort_values(by="sim", ascending=False, inplace=True)
        book_sim.sort_values(by="sim", ascending=False, inplace=True)
        return movie_sim, book_sim

    def _collab_filtering_search(self, vec: dict, dataset: Literal["movie", "book"] = "movie"):
        """Runs a collaborative filtering search on the movie or book datasets using the provided user vector.
        The vector should be a dictionary where keys are book ISBNs or movie IDs, and values are user ratings.
        Returns a pandas DataFrame of relevance scores for the specified dataset."""

        # Load the correct user-item matrix based on the dataset type
        if dataset == "movie":
            user_item_matrix = self._movie_ratings
        elif dataset == "book":
            user_item_matrix = self._book_ratings
        else:
            raise ValueError("Invalid dataset type. Choose either 'movie' or 'book'.")

        test_user_id = 0

        # Create a new user vector initialized with zeros for all items
        new_user_vector = pd.DataFrame(0, index=[0], columns=user_item_matrix.columns, dtype=float)

        # Assign ratings from the provided dictionary
        for item_id, rating in vec.items():
            if item_id in new_user_vector.columns:
                new_user_vector.loc[0, item_id] = rating  # Use provided rating instead of random assignment

        # Append the new user vector to the user-item matrix
        updated_user_item_matrix = pd.concat([new_user_vector, user_item_matrix], ignore_index=True)

        # Compute cosine similarity
        new_user_vector_values = new_user_vector.values
        cosine_sim = cosine_similarity(new_user_vector_values, updated_user_item_matrix.values)

        # Convert similarity scores to DataFrame
        similarity_df = pd.DataFrame({
            'userId': updated_user_item_matrix.index,
            'cosine_similarity': cosine_sim.flatten()
        }).sort_values(by='cosine_similarity', ascending=False)

        # Exclude the newly added user from the recommendations
        similarity_df = similarity_df[similarity_df['userId'] != 0]

        # Top 10 users to work with
        top_similar_users = similarity_df.head(10)['userId'].tolist()

        # Find items rated by similar users but not by the test user
        test_user_rated_items = set(
            updated_user_item_matrix.loc[test_user_id][updated_user_item_matrix.loc[test_user_id] > 0].index)
        similar_users_ratings = updated_user_item_matrix.loc[top_similar_users]

        # Find items that similar users rated but the test user hasn't rated
        recommendation_candidates = similar_users_ratings.drop(columns=test_user_rated_items, errors='ignore')

        # Calculate average ratings of these items from similar users
        recommendations = recommendation_candidates.mean().reset_index()
        recommendations.columns = ['item_id', 'avg_rating']

        # Sort recommendations by highest average rating
        recommendations = recommendations.sort_values(by='avg_rating', ascending=False)

        return recommendations

    def _content_filtering_search(self, vec, dataset: Literal["movie", "book"] = "movie", top_n = 10):
        """Runs a content-based filtering search on the movie or book datasets using the provided item vector.
        Returns a pandas dataframe of relevance scores for the specified movie/book dataset."""
        pass

# vec = np.array([-0.05660071994889969, 0.06133908286904482, -0.014848384027093438, 0.022485101540859215, -0.05432085870807928, -0.04370729878492591, -0.01629523834604274, 0.0016356951124118502, 0.022485122245721058, -0.0884352463460758, -0.06100492357041823, 0.025796888675125116, -0.023851050606572482, -0.03811251591906886, -0.030339759037861205, -0.03918281851461876, -0.025457297738487716, 0.06530532332440434, -0.04083945375960329, -0.061906378604800937, 0.02632128400541507, 0.05107281370145612, 0.00560399502729408, 0.017294503159729323, 0.006511450665194507, -0.027281504068570273, 0.0511855481067524, -0.02083204407893235, -0.1012533345173984, -0.045231608124468824, 0.007799217786818825, -0.032062315125236045, -0.09802242676959516, 0.010734810035003763, -0.11952565920893306, 0.07934360990692597, 0.011462797295963143, 0.0530096121604665, 0.0674276850537802, -0.06943694663748488, -0.031418687050129276, 0.02200430281488132, -0.002938977576735348, 0.029309955196459764, -0.03724452430225043, -0.03706368442911588, -0.02704235816392073, -0.0513277462302886, -0.025676522215371058, 0.013046924585874859, 0.04405854821448819, 0.01849974558210567, -0.047476548576026005, 0.013289368976432105, 0.07831099535919267, 0.08190814618501542, -0.035390649148118535, -0.13671839664881233, 0.06563508110737158, -0.006783834849261025, -0.04529170793747871, 0.00287861773250918, -0.023871602119300506, 0.06055100164978914, -0.012388131764706434, -0.06749904747524607, 0.04854879060776262, -0.009393620860405167, -0.012088976020169227, -0.04748092139846791, 0.033503626428151044, 0.015245212153129939, 0.053697965877879346, -0.050367047877997125, 0.02314601628093242, 0.045085936090394546, -0.11200904997659389, 0.003522674328272682, 0.0065630981920247276, -0.07757572502225896, 0.019940271238781924, -0.003978857294919431, 0.04609917721326275, 0.054875042496919636, 0.007193334565612909, 0.012420328743194821, -0.010435787399002121, -0.024581846371945208, -0.0295647674049533, -0.003282026413061346, 0.05980571143308002, 0.0075657155171410416, 0.012148378029834449, 0.1081628308601297, -0.023292896041717196, 0.047242084586851946, 0.08241202315083927, -0.015231030295706903, -0.0756401883137742, 0.026741314473952157, 0.021854832355271095, -0.029933704521760817, 0.07518867993482288, 0.016427751851529365, 0.06514416029846015, -0.04889485866698463, 0.052933375732590486, -0.04081285702463631, 0.005041057946597054, -0.021193691001935876, -0.004905639786254575, -0.10940149094147217, -0.00286863859334733, -0.09594214836321913, 0.07997932300664747, 0.06834859717910452, -0.00031974741752817203, 0.11637976813541777, -0.07125712572173021, 0.07035196436345503, -0.04780379349201366, 0.16200701534288395, -0.003643583962069302, 0.007308103987429286, -0.05824705688236403, -0.03469997124595435, -0.0762570416057574, 3.379760871389246e-34, 0.014253780224233372, -0.014970302317301062, -0.03259682350888663, 0.06500938308417066, -0.029955087625720675, 0.03292169074545103, -0.05768292380145287, 0.0365976893891818, -0.0061145688808272305, -0.031152349744007914, -0.02741598089508548, -0.04734540270091498, -0.0879715967590364, -0.021354117836048746, -0.013256285747924902, 0.01994300550952324, -0.039810753728013, -0.009823324203426326, 0.045626637156549125, -0.032853661789673055, -0.030084790868672967, 0.03286147286522813, 0.028610598270249185, 0.06672937074452857, -0.020293477559429292, 0.0076240084084938506, -0.012819167401578055, 0.003755840994841908, -0.07774519030521285, 0.046781230890134466, -0.011229574898665214, -0.006843693885039931, -0.02331987539843449, -0.07222264625853525, -0.09190947223643381, -0.047460288397685096, -0.016540682415335392, -0.04371436585098545, -0.0005920158387150178, 0.008042405446071123, -0.017135906227451186, -0.04014071451421347, -0.07849944691511267, -0.05046094719166392, -0.05968105897133691, 0.02730645458267392, 0.040429751739852735, 0.04862872989449652, -0.0204500248008512, 0.07913977454648184, -0.008546216098302008, -0.04636903092182912, 0.009519009025802307, -0.0038208046239878177, -0.08999583613397108, 0.010902048051759913, 0.006529275963813361, -0.04041016581107336, 0.07541985692049696, 0.011859633027801771, 0.05014503312653758, 0.06650104177831745, -0.009443188862943432, 0.09672457826468497, 0.009793489316826292, -0.0037049738603704037, -0.023996121047486576, -0.05602189259510583, -0.033424000849945075, -0.02932017749229014, -0.05588513791288791, -0.002700713502905333, -0.08676553101201075, -0.031517224389402444, 0.0078622305605261, -0.04039276954177149, -0.026958411863396366, -0.037419042843486475, -0.0986827881112134, 0.012090292904003798, 0.039097807345809886, 0.009307296778042729, 0.004893956485047577, -0.037293084056876244, -0.001180966367867114, -0.03349823286626166, 0.0424046858915963, -0.12018936251905855, 0.016920463246934806, 0.063560556587223, 0.056634416642151096, -0.04410619817529467, 0.02479353018252438, 0.0003440313699265883, 0.07182466459025809, -4.401073995451539e-33, 0.06891315932688476, -0.09289762781297119, 0.073007558046499, 0.019248768180450123, 0.025245663803923644, 0.026611261057676902, -0.13586928804556378, 0.03518393150021424, -0.008171402794908328, 0.0007580205250568269, -0.08702925377030997, 0.09642281062145555, 0.09611268166200619, -0.035900653182687994, 0.07770651072153338, -0.050624670553854625, 0.05775428176787428, -0.004434628639353992, 0.025452362744055, 0.03904125367992119, 0.03214071679006995, 0.004466095642590369, -0.1494802712909173, -0.09660459060319478, 0.006435069013110252, 0.02483091163110812, -0.020206063424979232, -0.054238821761096526, -0.04282847902924345, 0.06333845998925683, 0.028494676476930023, -0.02776568145418719, 0.05032452149143676, -0.020252937781319622, -0.030933481619474724, 0.02706561772919733, 0.05993423527384592, -0.06221666460030054, -0.009055769661305954, -0.05644114512070519, 0.0733113643078362, -0.0019285993337197918, 0.03518063666198088, 0.004542645323248405, 0.0230635319689669, -0.013863770422771437, 0.09751900896352697, 0.13735452271920776, 0.027469394254748848, -0.011687383932646539, -0.0273106196566628, 0.018697159612142786, 0.04781000580402394, -0.05706243930684427, 0.06386551496402594, -0.005705352358509038, 0.0162261041978536, -0.006505243183749692, 0.018458399953021096, -0.03696043083638654, -0.09143059890898526, -0.02534340481679972, 0.025582547165948266, 0.08003018961197576, -0.07603992798356497, 0.04456203246899551, -0.018258449278698095, 0.027111490093122196, 0.0101861199526731, -0.06664057957460905, -0.01233771822203847, -0.00536118498170761, -0.056610865757932116, -0.05807305049235744, 0.053011875664439746, 0.07468915508657908, 0.03432996962955565, 0.026995411366167583, -0.03477382289364659, -0.002206111052071959, 0.0816162571334959, 0.006517517889549649, 0.01174459623504068, -0.041131896704582706, 0.025046238654156686, -0.08935547657649012, 0.045149088820774716, -0.00601356001602164, -0.000270191312177627, -0.06942545432966712, 0.08805275688157718, 0.010949535582669187, 0.04219071795240699, -0.028967316411985463, 0.10680043449608582, -6.233925923091652e-08, -0.04158109542461731, 0.04106614874864226, 0.042654976383575495, -0.04368002664132055, 0.052935220291692224, -0.031057543274044634, 0.04976574327156315, 0.06644925999419882, 0.012159961606321879, 0.06510582870325426, 0.039571890510443804, 0.02215082641107643, 0.0019383981272193904, -0.0465104515803634, 0.05399425359451251, 0.04799447415759807, 0.014138738566768547, -0.04382471965803623, -0.011299698630008065, 0.016540206596103085, -0.01256948807000971, -0.08547338906061414, 0.10083981737508317, -0.04450308142760764, -0.002341092754609517, -0.011117757549764216, 0.011191021780213637, -0.11422896683595593, 0.06624233410283656, 0.07146913447744947, 0.080678249739426, -0.022580640259683395, 0.0030431555314501366, -0.0316310209831289, -0.01992372834434313, 0.005930669173567168, -0.04958959892107785, -0.0026680447130177443, 0.0884737256405146, -0.01679130597224263, 0.03289922958900608, -0.06593047382093303, 0.00836206869569018, 0.034488567847139724, -0.08938025456088884, -0.030850144123820453, 0.07977707480956338, -0.027680271543536073, -0.039577624203883485, -0.05118093530932891, -0.07777149019083741, 0.03485707205652258, 0.10987691741296304, -0.04542751196270731, 0.04463902663165926, 0.019609920644724933, 0.007211315841995599, 0.10776433481344223, -0.08972313494191263, -0.017982699982765724, 0.06151927074420225, 0.03436655378904306, 0.0016202686162719328, 0.029766538605034695])
# history = {"book": {458: 5.0, 1131: 4.5}, "movie": {1176: 4.3, 2109: 4.5, 2678: 4.0, 1323: 4.5, 543: 5.0, 1192: 4.9, 1567: 4.0}}
#
# rm = RecommendationManager()
# print(rm.get_recommendations(vec, history))
